context_id,question,response,latency,context_length,question_length,total_length
osdi24-sun-biao,What is the Abstract of this document?,"The Abstract of this document states: ""Llumnix is a dynamic scheduling system for LLM inference that supports request rescheduling across multiple model instances. It achieves better load balancing, reduces memory fragmentation, enforces request prioritization, and supports scalable auto-scaling. It introduces near-zero-downtime live migration of requests and outperforms INFaaS++ by up to 15Ã— in latency and achieves up to 36% cost savings.""

(Response delay: 0.29 seconds)",1.7837696489877999,3574,38,3612
osdi24-sun-biao,What is the Conclusion of this document?,"The Conclusion of this document states: ""Llumnix provides a unified architecture for LLM inference serving, inspired by OS-level abstractions. Through migration and dynamic scheduling, it balances performance, isolation, and cost in multi-tenant GPU clusters.""

(Response delay: 0.30 seconds)",1.1162038259208202,3574,40,3614
osdi24-sun-biao,What is the Introduction of this document?,"The Introduction of this document states: ""LLM inference workloads are heterogeneous and unpredictable. Llumnix proposes request rescheduling (like OS context switching) across model instances to balance load, mitigate fragmentation, and prioritize requests. It unifies multiple scheduling goals under a live migration mechanism.""

(Response delay: 0.34 seconds)",1.2918044298421592,3574,42,3616
sigcomm24-crux,What is the Introduction of this document?,"The Introduction of this document states: ""Modern GPU clusters face GPU underutilization due to communication contention among co-exech DLT jobs. Crux introduces GPU intensity as a priorit priorit metric and shows that current schedulers don't adequately handle inter-job contention.""

(Response delay: 0.38 seconds)",1.2488370179198682,3561,42,3603
sigcomm24-crux,What is the Conclusion of this document?,"The Conclusion of this document states: ""Crux introduces GPU intensity as a foundational metric for DLT communication scheduling. Through path selection, priority assignment and priority compression, it significantly improves cluster GPU utilization.""

(Response delay: 0.44 seconds)",1.1094459921587259,3561,40,3601
sigcomm24-crux,What is the Abstract of this document?,"The Abstract of this document states: ""Crux is a communication system that addresses inter-job communication contention in deep learning training (DLT) clusters, improving GPU utilization. By defining GPU intensity and tailoring scheduling accordingly Crux increases GPU utilization up to 23% over state-of-the-art approaches.""

(Response delay: 0.46 seconds)",1.4990500130224973,3561,38,3599
